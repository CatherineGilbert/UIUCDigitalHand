{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and set-up\n",
    "---\n",
    "> Uncomment as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Training DataFrames:\n",
    "\n",
    "trn_traits = pd.read_csv('training_data/trait_data.csv')\n",
    "trn_metadata = pd.read_csv('training_data/meta_data.csv')\n",
    "# trn_env_cov = pd.read_csv('training_data/env_cov.csv')\n",
    "# trn_soil = pd.read_csv('training_data/soil_data.csv')\n",
    "# trn_weather_season = pd.read_csv('training_data/weather_season.csv')\n",
    "# trn_weather_year = pd.read_csv('training_data/weather_year.csv')\n",
    "\n",
    "\n",
    "# Testing DataFrames:\n",
    "\n",
    "# tst_template = pd.read_csv('testing_data/template.csv')\n",
    "# tst_metadata = pd.read_csv('testing_data/meta_data.csv')\n",
    "# tst_env_cov = pd.read_csv('testing_data/env_cov.csv')\n",
    "# tst_soil = pd.read_csv('testing_data/soil_data.csv')\n",
    "# tst_weather_season = pd.read_csv('testing_data/weather_season.csv')\n",
    "# tst_weather_year = pd.read_csv('testing_data/weather_year.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = 6371000 # Earth Radius (m)\n",
    "def haversine_distance(lat1, lat2, lon1, lon2):\n",
    "    lat1, lat2, lon1, lon2 = map(np.radians, [lat1, lat2, lon1, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    \n",
    "    a = np.sin(dlat / 2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2.0)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    return c*R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Useful Column Subsets\n",
    "---\n",
    "\n",
    "This section is for meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Condensing 4 positions into 1 (center location)\n",
    "lat_cols = [c for c in trn_metadata.columns if c.startswith('Latitude')]\n",
    "lon_cols = [c for c in trn_metadata.columns if c.startswith('Longitude')]\n",
    "\n",
    "trn_metadata.loc[:, 'Latitude'] = trn_metadata[lat_cols].mean(axis=1)\n",
    "trn_metadata.loc[:, 'Longitude'] = trn_metadata[lon_cols].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Env</th>\n",
       "      <th>Experiment_Code</th>\n",
       "      <th>City</th>\n",
       "      <th>Farm</th>\n",
       "      <th>Field</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014</td>\n",
       "      <td>DEH1_2014</td>\n",
       "      <td>DEH1</td>\n",
       "      <td>Georgetown</td>\n",
       "      <td>Elbert N. &amp; Ann V. Carvel Research &amp; Education...</td>\n",
       "      <td>27AB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014</td>\n",
       "      <td>GAH1_2014</td>\n",
       "      <td>GAH1</td>\n",
       "      <td>Tifton</td>\n",
       "      <td>USDA - Bellflower experimental farm</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014</td>\n",
       "      <td>IAH1a_2014</td>\n",
       "      <td>IAH1</td>\n",
       "      <td>Ames</td>\n",
       "      <td>Worle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014</td>\n",
       "      <td>IAH1b_2014</td>\n",
       "      <td>IAH1</td>\n",
       "      <td>Ames</td>\n",
       "      <td>Worle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014</td>\n",
       "      <td>IAH1c_2014</td>\n",
       "      <td>IAH1</td>\n",
       "      <td>Ames</td>\n",
       "      <td>Worle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year         Env Experiment_Code        City  \\\n",
       "0  2014   DEH1_2014            DEH1  Georgetown   \n",
       "1  2014   GAH1_2014            GAH1      Tifton   \n",
       "2  2014  IAH1a_2014            IAH1        Ames   \n",
       "3  2014  IAH1b_2014            IAH1        Ames   \n",
       "4  2014  IAH1c_2014            IAH1        Ames   \n",
       "\n",
       "                                                Farm Field  Latitude  \\\n",
       "0  Elbert N. & Ann V. Carvel Research & Education...  27AB       NaN   \n",
       "1                USDA - Bellflower experimental farm    18       NaN   \n",
       "2                                              Worle   NaN       NaN   \n",
       "3                                              Worle   NaN       NaN   \n",
       "4                                              Worle   NaN       NaN   \n",
       "\n",
       "   Longitude  \n",
       "0        NaN  \n",
       "1        NaN  \n",
       "2        NaN  \n",
       "3        NaN  \n",
       "4        NaN  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_cols_important = [\n",
    "    'Year', 'Env', 'Experiment_Code', \n",
    "    'City', 'Farm', 'Field',\n",
    "    'Latitude', 'Longitude'\n",
    "]\n",
    "\n",
    "metadata_cols_interesting = [\n",
    "    'Year', 'Env', 'Experiment_Code', \n",
    "    'City', 'Farm', 'Field',\n",
    "    'Pre-plant_tillage_method(s)', 'In-season_tillage_method(s)',\n",
    "    'Previous_Crop', 'Irrigated',\n",
    "    'Latitude', 'Longitude'\n",
    "]\n",
    "\n",
    "metadata_cols_minimal = ['Env', 'Latitude', 'Longitude']\n",
    "\n",
    "trn_metadata = trn_metadata[metadata_cols_important]\n",
    "trn_metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is for trait_data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: define useful column subsets for trait_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Addressing Missing Locations\n",
    "---\n",
    "\n",
    "This works by first trying to match each Env with a missing location to the most similar Env whose location can be copied.\n",
    "\n",
    "The remaining values are just selected by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Locations:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Env</th>\n",
       "      <th>Experiment_Code</th>\n",
       "      <th>City</th>\n",
       "      <th>Farm</th>\n",
       "      <th>Field</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2014</td>\n",
       "      <td>TXH2_2014</td>\n",
       "      <td>TXH2</td>\n",
       "      <td>Halfway</td>\n",
       "      <td>Halfway</td>\n",
       "      <td>pivot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2015</td>\n",
       "      <td>TXH2_2015</td>\n",
       "      <td>TXH2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2016</td>\n",
       "      <td>TXH2_2016</td>\n",
       "      <td>TXH2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2017</td>\n",
       "      <td>ILH1_2017</td>\n",
       "      <td>ILH1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>2017</td>\n",
       "      <td>INH1_2017</td>\n",
       "      <td>INH1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>2017</td>\n",
       "      <td>TXH2_2017</td>\n",
       "      <td>TXH2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>2018</td>\n",
       "      <td>TXH2_2018</td>\n",
       "      <td>TXH2</td>\n",
       "      <td>Lubbock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2019</td>\n",
       "      <td>NEH2_2019</td>\n",
       "      <td>NEH2</td>\n",
       "      <td>Lincoln</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>2019</td>\n",
       "      <td>TXH4_2019</td>\n",
       "      <td>TXH4</td>\n",
       "      <td>Lubbock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year        Env Experiment_Code     City     Farm  Field  Latitude  \\\n",
       "22   2014  TXH2_2014            TXH2  Halfway  Halfway  pivot       NaN   \n",
       "48   2015  TXH2_2015            TXH2      NaN      NaN    NaN       NaN   \n",
       "75   2016  TXH2_2016            TXH2      NaN      NaN    NaN       NaN   \n",
       "88   2017  ILH1_2017            ILH1      NaN      NaN    NaN       NaN   \n",
       "89   2017  INH1_2017            INH1      NaN      NaN    NaN       NaN   \n",
       "105  2017  TXH2_2017            TXH2      NaN      NaN    NaN       NaN   \n",
       "134  2018  TXH2_2018            TXH2  Lubbock      NaN    NaN       NaN   \n",
       "152  2019  NEH2_2019            NEH2  Lincoln      NaN    NaN       NaN   \n",
       "162  2019  TXH4_2019            TXH4  Lubbock      NaN    NaN       NaN   \n",
       "\n",
       "     Longitude  \n",
       "22         NaN  \n",
       "48         NaN  \n",
       "75         NaN  \n",
       "88         NaN  \n",
       "89         NaN  \n",
       "105        NaN  \n",
       "134        NaN  \n",
       "152        NaN  \n",
       "162        NaN  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, self-join meta_data on Experiment_Code and City.\n",
    "# This makes a table where each Env has a number of rows that share at least Experiment_Code and City.\n",
    "merged = trn_metadata.merge(\n",
    "    trn_metadata,  # Join with itself\n",
    "    on=['Experiment_Code', 'City'], \n",
    "    suffixes=('', '_other')\n",
    ")\n",
    "\n",
    "# Filter out self matches, and narrow down to rows that are missing their location, but the comparable Env still has a location.\n",
    "merged = merged[(merged['Year'] != merged['Year_other']) & merged['Latitude'].isna() & merged['Latitude_other'].notna()]\n",
    "\n",
    "# Now, most of the Envs with a missing location will have multiple comparable Envs\n",
    "# Assign each of those other Envs a match_priority value, which determines how closely they match\n",
    "# Two Envs that share a 'Field' will have priority value 3, sharing a 'Farm' will get 2, and only sharing 'City' will get 1.\n",
    "merged['match_priority'] = (\n",
    "    (merged['Field'] == merged['Field_other']).astype(int) +\n",
    "    (merged['Farm'] == merged['Farm_other']).astype(int) +\n",
    "    1\n",
    ")\n",
    "\n",
    "merged = merged.sort_values(by=['Env', 'match_priority'], ascending=[True, False]) # Sort to put the highest priority match for each Env first.\n",
    "best_matches = merged.groupby('Env').first().reset_index() # Get one row per Env again, but only keep the highest priority match\n",
    "best_matches = best_matches[['Env', 'Latitude_other', 'Longitude_other']] # Narrow down to just important columns\n",
    "\n",
    "# I have manually determined which Envs were not able to find a match, and found a suitable location:\n",
    "curated_locations = [\n",
    "    ['ILH1_2017', 40.060724, 88.233881],                    # Choosing MF-500, copying from ILH1_2016\n",
    "    ['INH1_2017', 40.478760, 86.989820],                    # Choosing Purdue Acre 54 North, copying from INH1_2016\n",
    "    ['NEH2_2019', 40.86073680542686, -96.6139217242634],    # Choosing a larger field near the Havelock Research Farm in Lincoln, NE\n",
    "    ['TXH2_2014', 34.19196292257452, -101.96587766472442],  # Chose a random center pivot field after searching 'Halfway, TX'\n",
    "    ['TXH2_2015', 33.683219771598594, -101.8228099023082],  # | For these, I am just going with a field next to the\n",
    "    ['TXH2_2016', 33.683219771598594, -101.8228099023082],  # | Texas A&M AgriLife Research & Extension Center at Lubbock\n",
    "    ['TXH2_2017', 33.683219771598594, -101.8228099023082],  # | \n",
    "    ['TXH2_2018', 33.683219771598594, -101.8228099023082],  # | It should be accurate for the ones listed as Lubbock, and close enough for the others. \n",
    "    ['TXH4_2019', 33.683219771598594, -101.8228099023082]   # /\n",
    "]\n",
    "curated_locations_df = pd.DataFrame(curated_locations, columns=['Env', 'Latitude_other', 'Longitude_other'])\n",
    "best_matches = pd.concat([best_matches, curated_locations_df], ignore_index=True) # Concatenate my curated locations to the matches.\n",
    "\n",
    "# Finally, I align my new locations with the meta_data df, and fill in the missing values using my new values.\n",
    "aligned_matches = trn_metadata.merge(best_matches, on='Env', how='left')\n",
    "trn_metadata['Latitude'] = trn_metadata['Latitude'].fillna(aligned_matches['Latitude_other'])\n",
    "trn_metadata['Longitude'] = trn_metadata['Longitude'].fillna(aligned_matches['Longitude_other'])\n",
    "\n",
    "print('Missing Locations:')\n",
    "trn_metadata[trn_metadata['Latitude'].isna()] # print the misisng locations to verify they are all taken care of "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Envirotyping Input\n",
    "---\n",
    "\n",
    "Input Variables:\n",
    "| Variable | Description | Collection Method |\n",
    "| --- | --- | --- |\n",
    "| Site | User site Identifier | Use 'Env' column |\n",
    "| Planting | Plating Date (mm/dd/yyyy) | use 'Date_Planted' column |\n",
    "| Latitude | Latitude of trial | use meta_data['Latitude'] |\n",
    "| Longitude | Longitude of trial | use meta_data['Longitude'] |\n",
    "| Crop | soybean or maize | 'maize' |\n",
    "| Genetics | Soybean: maturity group (0-6, by 1), Maize: RM (80-130, by 5) | ??? |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Env</th>\n",
       "      <th>Field_Location</th>\n",
       "      <th>Year</th>\n",
       "      <th>Date_Planted</th>\n",
       "      <th>Pollen_DAP_days</th>\n",
       "      <th>Silk_DAP_days</th>\n",
       "      <th>Date_Harvested</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Harvest_DAP_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEH1_2014</td>\n",
       "      <td>DEH1</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014-05-05</td>\n",
       "      <td>63.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2014-09-29</td>\n",
       "      <td>38.629357</td>\n",
       "      <td>-75.465693</td>\n",
       "      <td>147.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEH1_2014</td>\n",
       "      <td>DEH1</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014-05-05</td>\n",
       "      <td>61.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2014-09-29</td>\n",
       "      <td>38.629357</td>\n",
       "      <td>-75.465693</td>\n",
       "      <td>147.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DEH1_2014</td>\n",
       "      <td>DEH1</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014-05-05</td>\n",
       "      <td>63.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2014-09-29</td>\n",
       "      <td>38.629357</td>\n",
       "      <td>-75.465693</td>\n",
       "      <td>147.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DEH1_2014</td>\n",
       "      <td>DEH1</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014-05-05</td>\n",
       "      <td>61.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2014-09-29</td>\n",
       "      <td>38.629357</td>\n",
       "      <td>-75.465693</td>\n",
       "      <td>147.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DEH1_2014</td>\n",
       "      <td>DEH1</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014-05-05</td>\n",
       "      <td>63.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2014-09-29</td>\n",
       "      <td>38.629357</td>\n",
       "      <td>-75.465693</td>\n",
       "      <td>147.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173955</th>\n",
       "      <td>WIH3_2023</td>\n",
       "      <td>WIH3</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-04-26</td>\n",
       "      <td>81.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2023-11-14</td>\n",
       "      <td>44.115645</td>\n",
       "      <td>-89.544009</td>\n",
       "      <td>202.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173956</th>\n",
       "      <td>WIH3_2023</td>\n",
       "      <td>WIH3</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-04-26</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2023-11-14</td>\n",
       "      <td>44.115645</td>\n",
       "      <td>-89.544009</td>\n",
       "      <td>202.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173957</th>\n",
       "      <td>WIH3_2023</td>\n",
       "      <td>WIH3</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-04-26</td>\n",
       "      <td>78.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2023-11-14</td>\n",
       "      <td>44.115645</td>\n",
       "      <td>-89.544009</td>\n",
       "      <td>202.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173958</th>\n",
       "      <td>WIH3_2023</td>\n",
       "      <td>WIH3</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-04-26</td>\n",
       "      <td>84.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2023-11-14</td>\n",
       "      <td>44.115645</td>\n",
       "      <td>-89.544009</td>\n",
       "      <td>202.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173959</th>\n",
       "      <td>WIH3_2023</td>\n",
       "      <td>WIH3</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-04-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2023-11-14</td>\n",
       "      <td>44.115645</td>\n",
       "      <td>-89.544009</td>\n",
       "      <td>202.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>173960 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Env Field_Location  Year Date_Planted  Pollen_DAP_days  \\\n",
       "0       DEH1_2014           DEH1  2014   2014-05-05             63.0   \n",
       "1       DEH1_2014           DEH1  2014   2014-05-05             61.0   \n",
       "2       DEH1_2014           DEH1  2014   2014-05-05             63.0   \n",
       "3       DEH1_2014           DEH1  2014   2014-05-05             61.0   \n",
       "4       DEH1_2014           DEH1  2014   2014-05-05             63.0   \n",
       "...           ...            ...   ...          ...              ...   \n",
       "173955  WIH3_2023           WIH3  2023   2023-04-26             81.0   \n",
       "173956  WIH3_2023           WIH3  2023   2023-04-26             70.0   \n",
       "173957  WIH3_2023           WIH3  2023   2023-04-26             78.0   \n",
       "173958  WIH3_2023           WIH3  2023   2023-04-26             84.0   \n",
       "173959  WIH3_2023           WIH3  2023   2023-04-26              NaN   \n",
       "\n",
       "        Silk_DAP_days Date_Harvested   Latitude  Longitude  Harvest_DAP_days  \n",
       "0                67.0     2014-09-29  38.629357 -75.465693             147.0  \n",
       "1                63.0     2014-09-29  38.629357 -75.465693             147.0  \n",
       "2                65.0     2014-09-29  38.629357 -75.465693             147.0  \n",
       "3                63.0     2014-09-29  38.629357 -75.465693             147.0  \n",
       "4                65.0     2014-09-29  38.629357 -75.465693             147.0  \n",
       "...               ...            ...        ...        ...               ...  \n",
       "173955           82.0     2023-11-14  44.115645 -89.544009             202.0  \n",
       "173956           70.0     2023-11-14  44.115645 -89.544009             202.0  \n",
       "173957           80.0     2023-11-14  44.115645 -89.544009             202.0  \n",
       "173958          100.0     2023-11-14  44.115645 -89.544009             202.0  \n",
       "173959           90.0     2023-11-14  44.115645 -89.544009             202.0  \n",
       "\n",
       "[173960 rows x 10 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et_trait_cols = ['Env', 'Field_Location', 'Year', 'Date_Planted']\n",
    "# et_genetic_cols = ['Hybrid', 'Hybrid_orig_name'] # Unfortunately, none of the materials provided seem to list maturities for the hybrids\n",
    "et_timing_cols = ['Pollen_DAP_days', 'Silk_DAP_days', 'Date_Harvested']\n",
    "\n",
    "et_input = trn_traits[et_trait_cols + et_timing_cols]\n",
    "et_input = et_input.merge(trn_metadata[metadata_cols_minimal], on='Env')\n",
    "\n",
    "# Convert Date columns to_datetime\n",
    "et_input['Date_Planted'] = pd.to_datetime(et_input['Date_Planted'], format='%m/%d/%y')\n",
    "if 'Date_Harvested' in et_input: et_input['Date_Harvested'] = pd.to_datetime(et_input['Date_Harvested'], format='%m/%d/%y')\n",
    "\n",
    "et_input['Harvest_DAP_days'] = (et_input['Date_Harvested'] - et_input['Date_Planted']).dt.days\n",
    "et_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "---\n",
    "\n",
    "Everything below here is notes and experiments in progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Env</th>\n",
       "      <th>Field_Location</th>\n",
       "      <th>Year</th>\n",
       "      <th>Date_Planted</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Harvest_DAP_days</th>\n",
       "      <th>Pollen_DAP_days</th>\n",
       "      <th>Silk_DAP_days</th>\n",
       "      <th>Date_Harvested</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARH1_2016</td>\n",
       "      <td>ARH1</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016-04-07</td>\n",
       "      <td>34.729520</td>\n",
       "      <td>-90.760356</td>\n",
       "      <td>145.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>2016-08-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ARH1_2017</td>\n",
       "      <td>ARH1</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>34.727252</td>\n",
       "      <td>-90.760326</td>\n",
       "      <td>147.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>2017-09-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARH1_2018</td>\n",
       "      <td>ARH1</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018-04-25</td>\n",
       "      <td>34.729679</td>\n",
       "      <td>-90.760345</td>\n",
       "      <td>129.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>2018-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ARH2_2016</td>\n",
       "      <td>ARH2</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>35.838614</td>\n",
       "      <td>-90.665302</td>\n",
       "      <td>200.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>2016-11-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ARH2_2017</td>\n",
       "      <td>ARH2</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017-04-25</td>\n",
       "      <td>35.674181</td>\n",
       "      <td>-90.075270</td>\n",
       "      <td>144.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2017-09-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>WIH2_2023</td>\n",
       "      <td>WIH2</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-05-11</td>\n",
       "      <td>43.304243</td>\n",
       "      <td>-89.384146</td>\n",
       "      <td>200.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2023-11-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>WIH3_2020</td>\n",
       "      <td>WIH3</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020-05-21</td>\n",
       "      <td>44.115703</td>\n",
       "      <td>-89.544913</td>\n",
       "      <td>171.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2020-11-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>WIH3_2021</td>\n",
       "      <td>WIH3</td>\n",
       "      <td>2021</td>\n",
       "      <td>2021-04-29</td>\n",
       "      <td>44.114305</td>\n",
       "      <td>-89.544225</td>\n",
       "      <td>159.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2021-10-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>WIH3_2022</td>\n",
       "      <td>WIH3</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-05-16</td>\n",
       "      <td>44.119050</td>\n",
       "      <td>-89.556345</td>\n",
       "      <td>169.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2022-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>WIH3_2023</td>\n",
       "      <td>WIH3</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-04-26</td>\n",
       "      <td>44.115645</td>\n",
       "      <td>-89.544009</td>\n",
       "      <td>202.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2023-11-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>272 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Env Field_Location  Year Date_Planted   Latitude  Longitude  \\\n",
       "0    ARH1_2016           ARH1  2016   2016-04-07  34.729520 -90.760356   \n",
       "1    ARH1_2017           ARH1  2017   2017-04-17  34.727252 -90.760326   \n",
       "2    ARH1_2018           ARH1  2018   2018-04-25  34.729679 -90.760345   \n",
       "3    ARH2_2016           ARH2  2016   2016-04-23  35.838614 -90.665302   \n",
       "4    ARH2_2017           ARH2  2017   2017-04-25  35.674181 -90.075270   \n",
       "..         ...            ...   ...          ...        ...        ...   \n",
       "267  WIH2_2023           WIH2  2023   2023-05-11  43.304243 -89.384146   \n",
       "268  WIH3_2020           WIH3  2020   2020-05-21  44.115703 -89.544913   \n",
       "269  WIH3_2021           WIH3  2021   2021-04-29  44.114305 -89.544225   \n",
       "270  WIH3_2022           WIH3  2022   2022-05-16  44.119050 -89.556345   \n",
       "271  WIH3_2023           WIH3  2023   2023-04-26  44.115645 -89.544009   \n",
       "\n",
       "     Harvest_DAP_days  Pollen_DAP_days  Silk_DAP_days Date_Harvested  \n",
       "0               145.0             67.0           69.0     2016-08-30  \n",
       "1               147.0             65.0           71.0     2017-09-11  \n",
       "2               129.0             58.0           69.0     2018-09-01  \n",
       "3               200.0             61.0           62.0     2016-11-09  \n",
       "4               144.0             62.0           64.0     2017-09-16  \n",
       "..                ...              ...            ...            ...  \n",
       "267             200.0             78.0           79.0     2023-11-27  \n",
       "268             171.0             62.0           63.0     2020-11-08  \n",
       "269             159.0             76.0           78.0     2021-10-05  \n",
       "270             169.0             71.0           70.0     2022-11-01  \n",
       "271             202.0             82.0           84.0     2023-11-14  \n",
       "\n",
       "[272 rows x 10 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The purpose of this cell is to try to fill in missing value in `cols_to_fill`\n",
    "# It kinda works, but there are still 9 Pollen, and 10 Silk days that aren't filled since there is no data for IAH1/TXH4 to use.\n",
    "agg_func = lambda x: x.mode().min() # Aggregate columns by finding the most common value for that group (and break ties with min)\n",
    "\n",
    "cols_to_fill = ['Pollen_DAP_days', 'Silk_DAP_days', 'Date_Harvested']\n",
    "per_env = et_input.groupby('Env', as_index=False).agg(agg_func)\n",
    "\n",
    "# What this does is get a row for each location (e.g. ILH1) and has the (smallest) mode for that value,\n",
    "# Then any gaps in the data that was grouped by 'Env' are filled by the data that was grouped by the larger 'Field_Location'\n",
    "test = per_env.merge(et_input.groupby('Field_Location').agg({c: agg_func for c in cols_to_fill}), on='Field_Location', how='left')\n",
    "for col in cols_to_fill:\n",
    "    test[col] = test[f'{col}_x'].fillna(test[f'{col}_y'])\n",
    "    test = test.drop(columns=[f'{col}_x', f'{col}_y'])\n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pollen_DAP_days       0\n",
       "Silk_DAP_days         0\n",
       "Date_Harvested     7572\n",
       "dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the best values for these columns to fill in gaps by copying over valuse from the most similar trial(s)\n",
    "per_env = et_input.groupby(['Field_Location', 'Env']).agg({\n",
    "    'Date_Planted': lambda x: x.mode().min(), \n",
    "    'Pollen_DAP_days': lambda x: x.mode().min(),\n",
    "    'Silk_DAP_days': lambda x: x.mode().min(),\n",
    "    'Date_Harvested': lambda x: x.mode().min()\n",
    "}).reset_index()\n",
    "\n",
    "\n",
    "# Backup values to fill in the ones that are still missing after grouping by Env\n",
    "per_floc = trn_traits.groupby('Field_Location').agg({\n",
    "    'Pollen_DAP_days': lambda x: x.mode().min(),\n",
    "    'Silk_DAP_days': lambda x: x.mode().min(),\n",
    "    'Date_Harvested': lambda x: x.mode().min()\n",
    "})\n",
    "\n",
    "test = per_env.merge(per_floc, on='Field_Location', how='left')\n",
    "\n",
    "merge_cols = ['Pollen_DAP_days', 'Silk_DAP_days', 'Date_Harvested']\n",
    "for col in merge_cols:\n",
    "    test[col] = test[f'{col}_x'].fillna(test[f'{col}_y'])\n",
    "    test = test.drop(columns=[f'{col}_x', f'{col}_y'])\n",
    "\n",
    "# per_env\n",
    "# per_floc\n",
    "# et_input['Date_Planted'] = et_input['Date_Planted'].fillna(et_input.merge(plantings, on='Env', how='left')['Date_Planted_y'])\n",
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Env</th>\n",
       "      <th>Year</th>\n",
       "      <th>Date_Planted_x</th>\n",
       "      <th>Pollen_DAP_days</th>\n",
       "      <th>Silk_DAP_days</th>\n",
       "      <th>Date_Harvested</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Harvest_DAP_days</th>\n",
       "      <th>Date_Planted_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEH1_2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014-05-05</td>\n",
       "      <td>63.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2014-09-29</td>\n",
       "      <td>38.629357</td>\n",
       "      <td>-75.465693</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2014-05-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEH1_2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014-05-05</td>\n",
       "      <td>61.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2014-09-29</td>\n",
       "      <td>38.629357</td>\n",
       "      <td>-75.465693</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2014-05-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DEH1_2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014-05-05</td>\n",
       "      <td>63.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2014-09-29</td>\n",
       "      <td>38.629357</td>\n",
       "      <td>-75.465693</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2014-05-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DEH1_2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014-05-05</td>\n",
       "      <td>61.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2014-09-29</td>\n",
       "      <td>38.629357</td>\n",
       "      <td>-75.465693</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2014-05-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DEH1_2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014-05-05</td>\n",
       "      <td>63.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2014-09-29</td>\n",
       "      <td>38.629357</td>\n",
       "      <td>-75.465693</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2014-05-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173955</th>\n",
       "      <td>WIH3_2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-04-26</td>\n",
       "      <td>81.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2023-11-14</td>\n",
       "      <td>44.115645</td>\n",
       "      <td>-89.544009</td>\n",
       "      <td>202.0</td>\n",
       "      <td>2023-04-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173956</th>\n",
       "      <td>WIH3_2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-04-26</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2023-11-14</td>\n",
       "      <td>44.115645</td>\n",
       "      <td>-89.544009</td>\n",
       "      <td>202.0</td>\n",
       "      <td>2023-04-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173957</th>\n",
       "      <td>WIH3_2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-04-26</td>\n",
       "      <td>78.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2023-11-14</td>\n",
       "      <td>44.115645</td>\n",
       "      <td>-89.544009</td>\n",
       "      <td>202.0</td>\n",
       "      <td>2023-04-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173958</th>\n",
       "      <td>WIH3_2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-04-26</td>\n",
       "      <td>84.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2023-11-14</td>\n",
       "      <td>44.115645</td>\n",
       "      <td>-89.544009</td>\n",
       "      <td>202.0</td>\n",
       "      <td>2023-04-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173959</th>\n",
       "      <td>WIH3_2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-04-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2023-11-14</td>\n",
       "      <td>44.115645</td>\n",
       "      <td>-89.544009</td>\n",
       "      <td>202.0</td>\n",
       "      <td>2023-04-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>173960 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Env  Year Date_Planted_x  Pollen_DAP_days  Silk_DAP_days  \\\n",
       "0       DEH1_2014  2014     2014-05-05             63.0           67.0   \n",
       "1       DEH1_2014  2014     2014-05-05             61.0           63.0   \n",
       "2       DEH1_2014  2014     2014-05-05             63.0           65.0   \n",
       "3       DEH1_2014  2014     2014-05-05             61.0           63.0   \n",
       "4       DEH1_2014  2014     2014-05-05             63.0           65.0   \n",
       "...           ...   ...            ...              ...            ...   \n",
       "173955  WIH3_2023  2023     2023-04-26             81.0           82.0   \n",
       "173956  WIH3_2023  2023     2023-04-26             70.0           70.0   \n",
       "173957  WIH3_2023  2023     2023-04-26             78.0           80.0   \n",
       "173958  WIH3_2023  2023     2023-04-26             84.0          100.0   \n",
       "173959  WIH3_2023  2023     2023-04-26              NaN           90.0   \n",
       "\n",
       "       Date_Harvested   Latitude  Longitude  Harvest_DAP_days Date_Planted_y  \n",
       "0          2014-09-29  38.629357 -75.465693             147.0     2014-05-05  \n",
       "1          2014-09-29  38.629357 -75.465693             147.0     2014-05-05  \n",
       "2          2014-09-29  38.629357 -75.465693             147.0     2014-05-05  \n",
       "3          2014-09-29  38.629357 -75.465693             147.0     2014-05-05  \n",
       "4          2014-09-29  38.629357 -75.465693             147.0     2014-05-05  \n",
       "...               ...        ...        ...               ...            ...  \n",
       "173955     2023-11-14  44.115645 -89.544009             202.0     2023-04-26  \n",
       "173956     2023-11-14  44.115645 -89.544009             202.0     2023-04-26  \n",
       "173957     2023-11-14  44.115645 -89.544009             202.0     2023-04-26  \n",
       "173958     2023-11-14  44.115645 -89.544009             202.0     2023-04-26  \n",
       "173959     2023-11-14  44.115645 -89.544009             202.0     2023-04-26  \n",
       "\n",
       "[173960 rows x 10 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Consider trying to fill in planting/harvest dates by looking at the other crops in the same plot/experiment/year\n",
    "planting_dates = et_input[['Env', 'Date_Planted']].drop_duplicates(subset='Env', keep='first').reset_index(drop=True)\n",
    "\n",
    "aligned_planting_dates = et_input.merge(planting_dates, on='Env', how='left')\n",
    "\n",
    "aligned_planting_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Env</th>\n",
       "      <th>Date_Planted</th>\n",
       "      <th>Year</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Pollen_DAP_days</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Silk_DAP_days</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Date_Harvested</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Harvest_DAP_days</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>first</th>\n",
       "      <th>first</th>\n",
       "      <th>first</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>set</th>\n",
       "      <th>nunique</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARH1_2016</td>\n",
       "      <td>2016-04-07</td>\n",
       "      <td>2016</td>\n",
       "      <td>34.729520</td>\n",
       "      <td>-90.760356</td>\n",
       "      <td>69.004090</td>\n",
       "      <td>2.658882</td>\n",
       "      <td>70.580777</td>\n",
       "      <td>3.107718</td>\n",
       "      <td>{2016-08-30 00:00:00}</td>\n",
       "      <td>1</td>\n",
       "      <td>145.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ARH1_2017</td>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>2017</td>\n",
       "      <td>34.727252</td>\n",
       "      <td>-90.760326</td>\n",
       "      <td>66.238208</td>\n",
       "      <td>3.328699</td>\n",
       "      <td>67.530660</td>\n",
       "      <td>3.108595</td>\n",
       "      <td>{2017-09-11 00:00:00}</td>\n",
       "      <td>1</td>\n",
       "      <td>147.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARH1_2018</td>\n",
       "      <td>2018-04-25</td>\n",
       "      <td>2018</td>\n",
       "      <td>34.729679</td>\n",
       "      <td>-90.760345</td>\n",
       "      <td>60.249509</td>\n",
       "      <td>2.682442</td>\n",
       "      <td>65.487230</td>\n",
       "      <td>3.525823</td>\n",
       "      <td>{2018-09-01 00:00:00}</td>\n",
       "      <td>1</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ARH2_2016</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>2016</td>\n",
       "      <td>35.838614</td>\n",
       "      <td>-90.665302</td>\n",
       "      <td>63.277433</td>\n",
       "      <td>2.907575</td>\n",
       "      <td>64.801242</td>\n",
       "      <td>3.187410</td>\n",
       "      <td>{2016-11-09 00:00:00}</td>\n",
       "      <td>1</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ARH2_2017</td>\n",
       "      <td>2017-04-25</td>\n",
       "      <td>2017</td>\n",
       "      <td>35.674181</td>\n",
       "      <td>-90.075270</td>\n",
       "      <td>63.654255</td>\n",
       "      <td>3.454486</td>\n",
       "      <td>65.316489</td>\n",
       "      <td>3.583420</td>\n",
       "      <td>{2017-09-16 00:00:00}</td>\n",
       "      <td>1</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>WIH2_2023</td>\n",
       "      <td>2023-05-11</td>\n",
       "      <td>2023</td>\n",
       "      <td>43.304243</td>\n",
       "      <td>-89.384146</td>\n",
       "      <td>78.613148</td>\n",
       "      <td>3.058423</td>\n",
       "      <td>79.927939</td>\n",
       "      <td>3.166456</td>\n",
       "      <td>{2023-11-27 00:00:00}</td>\n",
       "      <td>1</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>WIH3_2020</td>\n",
       "      <td>2020-05-21</td>\n",
       "      <td>2020</td>\n",
       "      <td>44.115703</td>\n",
       "      <td>-89.544913</td>\n",
       "      <td>61.591216</td>\n",
       "      <td>4.950017</td>\n",
       "      <td>63.625000</td>\n",
       "      <td>5.060840</td>\n",
       "      <td>{2020-11-08 00:00:00}</td>\n",
       "      <td>1</td>\n",
       "      <td>171.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>WIH3_2021</td>\n",
       "      <td>2021-04-29</td>\n",
       "      <td>2021</td>\n",
       "      <td>44.114305</td>\n",
       "      <td>-89.544225</td>\n",
       "      <td>77.511905</td>\n",
       "      <td>3.929731</td>\n",
       "      <td>79.077453</td>\n",
       "      <td>4.472813</td>\n",
       "      <td>{2021-10-05 00:00:00}</td>\n",
       "      <td>1</td>\n",
       "      <td>159.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>WIH3_2022</td>\n",
       "      <td>2022-05-16</td>\n",
       "      <td>2022</td>\n",
       "      <td>44.119050</td>\n",
       "      <td>-89.556345</td>\n",
       "      <td>69.752595</td>\n",
       "      <td>3.429817</td>\n",
       "      <td>71.300518</td>\n",
       "      <td>3.477488</td>\n",
       "      <td>{2022-11-01 00:00:00}</td>\n",
       "      <td>1</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>WIH3_2023</td>\n",
       "      <td>2023-04-26</td>\n",
       "      <td>2023</td>\n",
       "      <td>44.115645</td>\n",
       "      <td>-89.544009</td>\n",
       "      <td>80.892086</td>\n",
       "      <td>3.720778</td>\n",
       "      <td>83.621928</td>\n",
       "      <td>4.968916</td>\n",
       "      <td>{2023-11-14 00:00:00}</td>\n",
       "      <td>1</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Env Date_Planted  Year   Latitude  Longitude Pollen_DAP_days  \\\n",
       "                            first      first      first            mean   \n",
       "0    ARH1_2016   2016-04-07  2016  34.729520 -90.760356       69.004090   \n",
       "1    ARH1_2017   2017-04-17  2017  34.727252 -90.760326       66.238208   \n",
       "2    ARH1_2018   2018-04-25  2018  34.729679 -90.760345       60.249509   \n",
       "3    ARH2_2016   2016-04-23  2016  35.838614 -90.665302       63.277433   \n",
       "4    ARH2_2017   2017-04-25  2017  35.674181 -90.075270       63.654255   \n",
       "..         ...          ...   ...        ...        ...             ...   \n",
       "283  WIH2_2023   2023-05-11  2023  43.304243 -89.384146       78.613148   \n",
       "284  WIH3_2020   2020-05-21  2020  44.115703 -89.544913       61.591216   \n",
       "285  WIH3_2021   2021-04-29  2021  44.114305 -89.544225       77.511905   \n",
       "286  WIH3_2022   2022-05-16  2022  44.119050 -89.556345       69.752595   \n",
       "287  WIH3_2023   2023-04-26  2023  44.115645 -89.544009       80.892086   \n",
       "\n",
       "              Silk_DAP_days                   Date_Harvested          \\\n",
       "          std          mean       std                    set nunique   \n",
       "0    2.658882     70.580777  3.107718  {2016-08-30 00:00:00}       1   \n",
       "1    3.328699     67.530660  3.108595  {2017-09-11 00:00:00}       1   \n",
       "2    2.682442     65.487230  3.525823  {2018-09-01 00:00:00}       1   \n",
       "3    2.907575     64.801242  3.187410  {2016-11-09 00:00:00}       1   \n",
       "4    3.454486     65.316489  3.583420  {2017-09-16 00:00:00}       1   \n",
       "..        ...           ...       ...                    ...     ...   \n",
       "283  3.058423     79.927939  3.166456  {2023-11-27 00:00:00}       1   \n",
       "284  4.950017     63.625000  5.060840  {2020-11-08 00:00:00}       1   \n",
       "285  3.929731     79.077453  4.472813  {2021-10-05 00:00:00}       1   \n",
       "286  3.429817     71.300518  3.477488  {2022-11-01 00:00:00}       1   \n",
       "287  3.720778     83.621928  4.968916  {2023-11-14 00:00:00}       1   \n",
       "\n",
       "    Harvest_DAP_days       \n",
       "                mean  std  \n",
       "0              145.0  0.0  \n",
       "1              147.0  0.0  \n",
       "2              129.0  0.0  \n",
       "3              200.0  0.0  \n",
       "4              144.0  0.0  \n",
       "..               ...  ...  \n",
       "283            200.0  0.0  \n",
       "284            171.0  0.0  \n",
       "285            159.0  0.0  \n",
       "286            169.0  0.0  \n",
       "287            202.0  0.0  \n",
       "\n",
       "[288 rows x 13 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = et_input.groupby(['Env', 'Date_Planted']).agg({\n",
    "    'Year': 'first', 'Latitude': 'first', 'Longitude': 'first',\n",
    "    'Pollen_DAP_days': ['mean', 'std'], 'Silk_DAP_days': ['mean', 'std'], 'Date_Harvested': [set, 'nunique'], 'Harvest_DAP_days': ['mean', 'std']\n",
    "}).reset_index()\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_input.to_csv('output_data/envirotype_input.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal 1: Get a single dataframe that contains all of the most important information for the competition\n",
    "metadata_cols_important = [\n",
    "    'Env', \n",
    "    'Location_Code',\n",
    "    'Year',\n",
    "    'Latitude',\n",
    "    'Longitude',\n",
    "    'Hybrid',\n",
    "    'Date_Planted',\n",
    "    # Date_Harvested, Pollen_DAP_days, Silk_DAP_days, Harvest_DAP_days?\n",
    "    # Check trait_data for some useful phenotype measurements\n",
    "    # Yield\n",
    "    # Decide whether we want any of the columns from metadata, like irrigation, methods, etc.\n",
    "]\n",
    "\n",
    "# Or, maybe make a few dfs? \n",
    "# I could have:\n",
    "#  - minimal meta_data\n",
    "#  - meta_data extra info\n",
    "#  - minimal trait_data\n",
    "#  - trait_data extra info\n",
    "#  - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal 2: Make a naive method of estimating yield by finding the year with the most similar conditons to 2024 and \n",
    "# copying over the yield values from that year for the given hybrids/locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "g2f",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
